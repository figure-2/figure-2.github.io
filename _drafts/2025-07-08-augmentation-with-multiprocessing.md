---
title: ë©€í‹°í”„ë¡œì„¸ì‹±
date: 2025-07-08 23:17:00 +0900
categories: [ ]
tags: [ "ê¸‰ë°œì§„ê±°ë¶ì´" ]
toc: true
comments: false
mermaid: true
math: true
---
## ğŸ“¦ ì‚¬ìš©í•˜ëŠ” python package

- Python 3.11+
- albumentations==2.0.8
- augraphy==8.2.6
- opencv-python==4.8.1
- numpy==1.26.4
- multiprocessing (ë‚´ì¥ ëª¨ë“ˆ)
- concurrent.futures (ë‚´ì¥ ëª¨ë“ˆ)

## ğŸš€ TL;DR

> ğŸ’¡ ì´ë¯¸ì§€ ì¦ê°•(Image Augmentation)ì€ ë¨¸ì‹ ëŸ¬ë‹ ëª¨ë¸ì˜ ì¼ë°˜í™” ì„±ëŠ¥ì„ ë†’ì´ëŠ” í•µì‹¬ ê¸°ë²•ì´ì§€ë§Œ, ëŒ€ìš©ëŸ‰ ë°ì´í„°ì…‹ì—ì„œëŠ” ì²˜ë¦¬ ì‹œê°„ì´ ë³‘ëª©ì´ ëœë‹¤!

- **albumentations**ëŠ” ë¹ ë¥´ê³  ìœ ì—°í•œ ì´ë¯¸ì§€ ì¦ê°• ë¼ì´ë¸ŒëŸ¬ë¦¬ë¡œ, ì»´í“¨í„° ë¹„ì „ ì‘ì—…ì— ìµœì í™”ë˜ì–´ ìˆë‹¤
- **augraphy**ëŠ” ë¬¸ì„œ ì´ë¯¸ì§€ì— íŠ¹í™”ëœ ì¦ê°• ê¸°ë²•ì„ ì œê³µí•˜ëŠ” ë¼ì´ë¸ŒëŸ¬ë¦¬ì´ë‹¤
- Pythonì˜ **ë©€í‹°í”„ë¡œì„¸ì‹±**ì„ í™œìš©í•˜ë©´ ì´ë¯¸ì§€ ì¦ê°• ì†ë„ë¥¼ CPU ì½”ì–´ ìˆ˜ë§Œí¼ í–¥ìƒì‹œí‚¬ ìˆ˜ ìˆë‹¤
- **ProcessPoolExecutor**ì™€ **multiprocessing.Pool**ì€ ê°ê°ì˜ ì¥ë‹¨ì ì´ ìˆìœ¼ë©°, ìƒí™©ì— ë”°ë¼ ì„ íƒí•´ì•¼ í•œë‹¤
- ê³µìœ  ë©”ëª¨ë¦¬ì™€ íš¨ìœ¨ì ì¸ ì§ë ¬í™”ë¥¼ í†µí•´ í”„ë¡œì„¸ìŠ¤ ê°„ í†µì‹  ì˜¤ë²„í—¤ë“œë¥¼ ìµœì†Œí™”í•  ìˆ˜ ìˆë‹¤
- ë°°ì¹˜ ì²˜ë¦¬ì™€ ì²­í¬ ë‹¨ìœ„ ì‘ì—… ë¶„ë°°ë¡œ ì¶”ê°€ì ì¸ ì„±ëŠ¥ í–¥ìƒì´ ê°€ëŠ¥í•˜ë‹¤

## ğŸ““ ì‹¤ìŠµ Jupyter Notebook

- [https://github.com/yuiyeong/notebooks/blob/main/computer_vision/multiprocessing_image_augmentation.ipynb](https://github.com/yuiyeong/notebooks/blob/main/computer_vision/multiprocessing_image_augmentation.ipynb)

## ğŸ–¼ï¸ ì´ë¯¸ì§€ ì¦ê°•ê³¼ ì²˜ë¦¬ ì†ë„ì˜ ë”œë ˆë§ˆ

### ì™œ ì´ë¯¸ì§€ ì¦ê°•ì´ í•„ìš”í•œê°€?

ì´ë¯¸ì§€ ì¦ê°•ì€ ì›ë³¸ ì´ë¯¸ì§€ì— ë‹¤ì–‘í•œ ë³€í™˜ì„ ì ìš©í•˜ì—¬ ë°ì´í„°ì…‹ì˜ ë‹¤ì–‘ì„±ì„ ì¦ê°€ì‹œí‚¤ëŠ” ê¸°ë²•ì´ë‹¤. ì´ëŠ” íŠ¹íˆ ë”¥ëŸ¬ë‹ ëª¨ë¸ì˜ ê³¼ì í•©ì„ ë°©ì§€í•˜ê³  ì¼ë°˜í™” ì„±ëŠ¥ì„ í–¥ìƒì‹œí‚¤ëŠ” ë° ì¤‘ìš”í•œ ì—­í• ì„ í•œë‹¤.

- **ë°ì´í„° ë¶€ì¡± ë¬¸ì œ í•´ê²°**: ì˜ë£Œ ì˜ìƒ, í¬ê·€ ì‚¬ë¡€ ë“± ë°ì´í„° ìˆ˜ì§‘ì´ ì–´ë ¤ìš´ ê²½ìš°
- **ëª¨ë¸ì˜ ê°•ê±´ì„± í–¥ìƒ**: ë‹¤ì–‘í•œ ì¡°ëª…, ê°ë„, ë…¸ì´ì¦ˆ ì¡°ê±´ì—ì„œë„ ì˜ ì‘ë™í•˜ë„ë¡
- **ë„ë©”ì¸ íŠ¹í™” ë³€í™˜**: ë¬¸ì„œ ì´ë¯¸ì§€ì˜ ê²½ìš° ì ‘í˜, ì–¼ë£©, ìŠ¤ìº” ë…¸ì´ì¦ˆ ë“± ì‹¤ì œ ìƒí™© ì¬í˜„

### ë‹¨ì¼ í”„ë¡œì„¸ìŠ¤ì˜ í•œê³„

ì¼ë°˜ì ì¸ ì´ë¯¸ì§€ ì¦ê°• íŒŒì´í”„ë¼ì¸ì€ ìˆœì°¨ì ìœ¼ë¡œ ì²˜ë¦¬ë˜ê¸° ë•Œë¬¸ì— ëŒ€ìš©ëŸ‰ ë°ì´í„°ì…‹ì—ì„œëŠ” ì‹œê°„ì´ ì˜¤ë˜ ê±¸ë¦°ë‹¤.

```python
import time
import cv2
import albumentations as A
from pathlib import Path

# ë‹¨ì¼ í”„ë¡œì„¸ìŠ¤ ì´ë¯¸ì§€ ì¦ê°• ì˜ˆì‹œ
def single_process_augmentation(image_paths, transform):
    augmented_images = []
    start_time = time.time()
    
    for img_path in image_paths:
        image = cv2.imread(str(img_path))
        augmented = transform(image=image)['image']
        augmented_images.append(augmented)
    
    end_time = time.time()
    print(f"ì²˜ë¦¬ ì‹œê°„: {end_time - start_time:.2f}ì´ˆ")
    print(f"ì´ë¯¸ì§€ë‹¹ í‰ê·  ì‹œê°„: {(end_time - start_time) / len(image_paths):.4f}ì´ˆ")
    
    return augmented_images

# ì¦ê°• íŒŒì´í”„ë¼ì¸ ì •ì˜
transform = A.Compose([
    A.RandomRotate90(),
    A.Flip(),
    A.RandomBrightnessContrast(p=0.5),
    A.GaussianBlur(p=0.3),
])

# 1000ê°œ ì´ë¯¸ì§€ ì²˜ë¦¬ ì‹œ ì•½ 50ì´ˆ ì†Œìš” (ì´ë¯¸ì§€ë‹¹ 0.05ì´ˆ)
```

[ì‹œê°ì  í‘œí˜„ ë„£ê¸°: ë‹¨ì¼ í”„ë¡œì„¸ìŠ¤ vs ë©€í‹°í”„ë¡œì„¸ì‹± ì²˜ë¦¬ ì‹œê°„ ë¹„êµ ê·¸ë˜í”„]

## ğŸ”§ ë©€í‹°í”„ë¡œì„¸ì‹± ê¸°ì´ˆ ê°œë…

### í”„ë¡œì„¸ìŠ¤ vs ìŠ¤ë ˆë“œ

íŒŒì´ì¬ì—ì„œ ë³‘ë ¬ ì²˜ë¦¬ë¥¼ êµ¬í˜„í•  ë•Œ ê°€ì¥ ë¨¼ì € ì´í•´í•´ì•¼ í•  ê°œë…ì€ **í”„ë¡œì„¸ìŠ¤**ì™€ **ìŠ¤ë ˆë“œ**ì˜ ì°¨ì´ë‹¤.

- **í”„ë¡œì„¸ìŠ¤**: ë…ë¦½ì ì¸ ë©”ëª¨ë¦¬ ê³µê°„ì„ ê°€ì§„ ì‹¤í–‰ ë‹¨ìœ„
- **ìŠ¤ë ˆë“œ**: í”„ë¡œì„¸ìŠ¤ ë‚´ì—ì„œ ë©”ëª¨ë¦¬ë¥¼ ê³µìœ í•˜ëŠ” ì‹¤í–‰ ë‹¨ìœ„

íŒŒì´ì¬ì˜ **GIL(Global Interpreter Lock)** ë•Œë¬¸ì— CPU ì§‘ì•½ì ì¸ ì‘ì—…ì—ì„œëŠ” ë©€í‹°ìŠ¤ë ˆë”©ë³´ë‹¤ ë©€í‹°í”„ë¡œì„¸ì‹±ì´ íš¨ê³¼ì ì´ë‹¤.

### Python 3.11ì˜ ë©€í‹°í”„ë¡œì„¸ì‹± ê°œì„ ì‚¬í•­

Python 3.11ì—ì„œëŠ” ë©€í‹°í”„ë¡œì„¸ì‹± ì„±ëŠ¥ì´ í¬ê²Œ ê°œì„ ë˜ì—ˆë‹¤:

- **ì‹œì‘ ì†ë„ í–¥ìƒ**: í”„ë¡œì„¸ìŠ¤ ìƒì„± ì˜¤ë²„í—¤ë“œ ê°ì†Œ
- **ë©”ëª¨ë¦¬ íš¨ìœ¨ì„±**: ê³µìœ  ë©”ëª¨ë¦¬ ê´€ë¦¬ ê°œì„ 
- **ì—ëŸ¬ ì²˜ë¦¬**: ë” ëª…í™•í•œ ì—ëŸ¬ ë©”ì‹œì§€ì™€ ë””ë²„ê¹… ì§€ì›

## ğŸš€ concurrent.futuresë¥¼ ì´ìš©í•œ ë©€í‹°í”„ë¡œì„¸ì‹±

### ProcessPoolExecutor ê¸°ë³¸ ì‚¬ìš©ë²•

`concurrent.futures` ëª¨ë“ˆì˜ `ProcessPoolExecutor`ëŠ” ê³ ìˆ˜ì¤€ ì¸í„°í˜ì´ìŠ¤ë¥¼ ì œê³µí•˜ì—¬ ë©€í‹°í”„ë¡œì„¸ì‹±ì„ ì‰½ê²Œ êµ¬í˜„í•  ìˆ˜ ìˆë‹¤.

```python
from concurrent.futures import ProcessPoolExecutor, as_completed
import albumentations as A
import cv2
from pathlib import Path
import time

# ì´ë¯¸ì§€ ì¦ê°• í•¨ìˆ˜
def augment_image(image_path, transform_config):
    """ë‹¨ì¼ ì´ë¯¸ì§€ë¥¼ ì¦ê°•í•˜ëŠ” í•¨ìˆ˜"""
    # ë§¤ í”„ë¡œì„¸ìŠ¤ë§ˆë‹¤ transform ì¬ìƒì„± (pickle ë¬¸ì œ íšŒí”¼)
    transform = A.Compose(transform_config)
    
    image = cv2.imread(str(image_path))
    if image is None:
        return None, image_path
    
    augmented = transform(image=image)['image']
    return augmented, image_path

# ë©€í‹°í”„ë¡œì„¸ì‹± ì¦ê°• í•¨ìˆ˜
def multiprocess_augmentation_futures(image_paths, transform_config, max_workers=None):
    """ProcessPoolExecutorë¥¼ ì‚¬ìš©í•œ ë©€í‹°í”„ë¡œì„¸ì‹± ì¦ê°•"""
    if max_workers is None:
        max_workers = min(32, (os.cpu_count() or 1) + 4)
    
    augmented_results = {}
    failed_paths = []
    
    start_time = time.time()
    
    with ProcessPoolExecutor(max_workers=max_workers) as executor:
        # ì‘ì—… ì œì¶œ
        future_to_path = {
            executor.submit(augment_image, path, transform_config): path 
            for path in image_paths
        }
        
        # ê²°ê³¼ ìˆ˜ì§‘
        for future in as_completed(future_to_path):
            path = future_to_path[future]
            try:
                result, original_path = future.result()
                if result is not None:
                    augmented_results[original_path] = result
                else:
                    failed_paths.append(original_path)
            except Exception as exc:
                print(f'{path} ì²˜ë¦¬ ì¤‘ ì—ëŸ¬ ë°œìƒ: {exc}')
                failed_paths.append(path)
    
    end_time = time.time()
    
    print(f"ì´ ì²˜ë¦¬ ì‹œê°„: {end_time - start_time:.2f}ì´ˆ")
    print(f"ì„±ê³µ: {len(augmented_results)}ê°œ, ì‹¤íŒ¨: {len(failed_paths)}ê°œ")
    print(f"ì´ë¯¸ì§€ë‹¹ í‰ê·  ì‹œê°„: {(end_time - start_time) / len(image_paths):.4f}ì´ˆ")
    
    return augmented_results, failed_paths

# ì‚¬ìš© ì˜ˆì‹œ
transform_config = [
    A.RandomRotate90(),
    A.Flip(),
    A.RandomBrightnessContrast(p=0.5),
    A.GaussianBlur(p=0.3),
]

image_paths = list(Path("./images").glob("*.jpg"))
results, failed = multiprocess_augmentation_futures(image_paths, transform_config)
# ì¶œë ¥: ì´ ì²˜ë¦¬ ì‹œê°„: 12.45ì´ˆ (4ë°° ë¹¨ë¼ì§!)
```

### ì²­í¬ ë‹¨ìœ„ ì²˜ë¦¬ë¡œ íš¨ìœ¨ì„± ë†’ì´ê¸°

ê°œë³„ ì´ë¯¸ì§€ë§ˆë‹¤ í”„ë¡œì„¸ìŠ¤ë¥¼ ìƒì„±í•˜ëŠ” ê²ƒë³´ë‹¤ ì²­í¬ ë‹¨ìœ„ë¡œ ì²˜ë¦¬í•˜ë©´ ì˜¤ë²„í—¤ë“œë¥¼ ì¤„ì¼ ìˆ˜ ìˆë‹¤.

```python
def augment_image_batch(image_paths_chunk, transform_config):
    """ì´ë¯¸ì§€ ë°°ì¹˜ë¥¼ ì²˜ë¦¬í•˜ëŠ” í•¨ìˆ˜"""
    transform = A.Compose(transform_config)
    results = []
    
    for img_path in image_paths_chunk:
        try:
            image = cv2.imread(str(img_path))
            if image is not None:
                augmented = transform(image=image)['image']
                results.append((img_path, augmented))
            else:
                results.append((img_path, None))
        except Exception as e:
            print(f"Error processing {img_path}: {e}")
            results.append((img_path, None))
    
    return results

def multiprocess_augmentation_chunks(image_paths, transform_config, 
                                   max_workers=None, chunk_size=None):
    """ì²­í¬ ë‹¨ìœ„ë¡œ ì´ë¯¸ì§€ë¥¼ ì²˜ë¦¬í•˜ëŠ” ë©€í‹°í”„ë¡œì„¸ì‹± í•¨ìˆ˜"""
    if max_workers is None:
        max_workers = os.cpu_count() or 1
    
    if chunk_size is None:
        chunk_size = max(1, len(image_paths) // (max_workers * 4))
    
    # ì´ë¯¸ì§€ ê²½ë¡œë¥¼ ì²­í¬ë¡œ ë¶„í• 
    chunks = [image_paths[i:i + chunk_size] 
              for i in range(0, len(image_paths), chunk_size)]
    
    all_results = {}
    start_time = time.time()
    
    with ProcessPoolExecutor(max_workers=max_workers) as executor:
        futures = [executor.submit(augment_image_batch, chunk, transform_config) 
                   for chunk in chunks]
        
        for future in as_completed(futures):
            chunk_results = future.result()
            for path, augmented in chunk_results:
                if augmented is not None:
                    all_results[path] = augmented
    
    end_time = time.time()
    print(f"ì²­í¬ ì²˜ë¦¬ ì‹œê°„: {end_time - start_time:.2f}ì´ˆ")
    
    return all_results

# ì²­í¬ ë‹¨ìœ„ ì²˜ë¦¬ëŠ” íŠ¹íˆ ì‘ì€ ì´ë¯¸ì§€ê°€ ë§ì„ ë•Œ íš¨ê³¼ì 
# ì¶œë ¥: ì²­í¬ ì²˜ë¦¬ ì‹œê°„: 10.23ì´ˆ
```

## ğŸ¯ multiprocessing.Poolì„ ì´ìš©í•œ ê³ ê¸‰ ê¸°ë²•

### Poolê³¼ imapì„ í™œìš©í•œ ì§„í–‰ë¥  í‘œì‹œ

`multiprocessing.Pool`ì€ ë” ì„¸ë°€í•œ ì œì–´ê°€ ê°€ëŠ¥í•˜ë©°, `imap`ì„ ì‚¬ìš©í•˜ë©´ ì‹¤ì‹œê°„ ì§„í–‰ë¥ ì„ í™•ì¸í•  ìˆ˜ ìˆë‹¤.

```python
import multiprocessing as mp
from tqdm import tqdm
import os

def augment_with_progress(args):
    """ì§„í–‰ë¥  í‘œì‹œë¥¼ ìœ„í•œ ë˜í¼ í•¨ìˆ˜"""
    image_path, transform_config = args
    transform = A.Compose(transform_config)
    
    try:
        image = cv2.imread(str(image_path))
        if image is not None:
            augmented = transform(image=image)['image']
            return image_path, augmented, True
        return image_path, None, False
    except Exception as e:
        return image_path, None, False

def multiprocess_with_progress(image_paths, transform_config, num_workers=None):
    """ì§„í–‰ë¥  í‘œì‹œê°€ ìˆëŠ” ë©€í‹°í”„ë¡œì„¸ì‹± ì¦ê°•"""
    if num_workers is None:
        num_workers = mp.cpu_count()
    
    # ì¸ì ì¤€ë¹„
    args = [(path, transform_config) for path in image_paths]
    
    results = {}
    failed_count = 0
    
    # í”„ë¡œì„¸ìŠ¤ í’€ ìƒì„±
    with mp.Pool(processes=num_workers) as pool:
        # imapì„ ì‚¬ìš©í•˜ì—¬ ìˆœì°¨ì ìœ¼ë¡œ ê²°ê³¼ ë°›ê¸°
        with tqdm(total=len(image_paths), desc="ì´ë¯¸ì§€ ì¦ê°• ì¤‘") as pbar:
            for path, augmented, success in pool.imap(augment_with_progress, args):
                if success:
                    results[path] = augmented
                else:
                    failed_count += 1
                pbar.update(1)
    
    print(f"ì²˜ë¦¬ ì™„ë£Œ: ì„±ê³µ {len(results)}ê°œ, ì‹¤íŒ¨ {failed_count}ê°œ")
    return results

# ì‚¬ìš© ì˜ˆì‹œ
results = multiprocess_with_progress(image_paths, transform_config)
# ì¶œë ¥: ì´ë¯¸ì§€ ì¦ê°• ì¤‘: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:11<00:00, 87.23it/s]
# ì²˜ë¦¬ ì™„ë£Œ: ì„±ê³µ 995ê°œ, ì‹¤íŒ¨ 5ê°œ
```

### ê³µìœ  ë©”ëª¨ë¦¬ë¥¼ í™œìš©í•œ ëŒ€ìš©ëŸ‰ ì´ë¯¸ì§€ ì²˜ë¦¬

ëŒ€ìš©ëŸ‰ ì´ë¯¸ì§€ë¥¼ ì²˜ë¦¬í•  ë•ŒëŠ” í”„ë¡œì„¸ìŠ¤ ê°„ ë°ì´í„° ì „ì†¡ ì˜¤ë²„í—¤ë“œê°€ í´ ìˆ˜ ìˆë‹¤. Python 3.8+ì—ì„œëŠ” ê³µìœ  ë©”ëª¨ë¦¬ë¥¼ í™œìš©í•  ìˆ˜ ìˆë‹¤.

```python
from multiprocessing import shared_memory
import numpy as np

def process_with_shared_memory(args):
    """ê³µìœ  ë©”ëª¨ë¦¬ë¥¼ ì‚¬ìš©í•œ ì´ë¯¸ì§€ ì²˜ë¦¬"""
    shm_name, shape, dtype, transform_config = args
    
    # ê³µìœ  ë©”ëª¨ë¦¬ ì—°ê²°
    existing_shm = shared_memory.SharedMemory(name=shm_name)
    image = np.ndarray(shape, dtype=dtype, buffer=existing_shm.buf)
    
    # ì¦ê°• ì ìš©
    transform = A.Compose(transform_config)
    augmented = transform(image=image)['image']
    
    # ê³µìœ  ë©”ëª¨ë¦¬ í•´ì œ
    existing_shm.close()
    
    return augmented

def multiprocess_shared_memory(images, transform_config, num_workers=None):
    """ê³µìœ  ë©”ëª¨ë¦¬ë¥¼ í™œìš©í•œ ë©€í‹°í”„ë¡œì„¸ì‹±"""
    if num_workers is None:
        num_workers = mp.cpu_count()
    
    shared_memories = []
    args_list = []
    
    # ê° ì´ë¯¸ì§€ë¥¼ ê³µìœ  ë©”ëª¨ë¦¬ì— ì €ì¥
    for img in images:
        shm = shared_memory.SharedMemory(create=True, size=img.nbytes)
        shared_array = np.ndarray(img.shape, dtype=img.dtype, buffer=shm.buf)
        shared_array[:] = img[:]
        
        shared_memories.append(shm)
        args_list.append((shm.name, img.shape, img.dtype, transform_config))
    
    # ë©€í‹°í”„ë¡œì„¸ì‹± ì‹¤í–‰
    with mp.Pool(processes=num_workers) as pool:
        results = pool.map(process_with_shared_memory, args_list)
    
    # ê³µìœ  ë©”ëª¨ë¦¬ ì •ë¦¬
    for shm in shared_memories:
        shm.close()
        shm.unlink()
    
    return results

# ëŒ€ìš©ëŸ‰ ì´ë¯¸ì§€ ë°°ì—´ì— íŠ¹íˆ íš¨ê³¼ì 
# ë©”ëª¨ë¦¬ ë³µì‚¬ ì˜¤ë²„í—¤ë“œ ì—†ì´ ì²˜ë¦¬ ê°€ëŠ¥
```

## ğŸ“„ Augraphyë¥¼ í™œìš©í•œ ë¬¸ì„œ ì´ë¯¸ì§€ ì¦ê°•

### Augraphy ì†Œê°œ

**Augraphy**ëŠ” ë¬¸ì„œ ì´ë¯¸ì§€ì— íŠ¹í™”ëœ ì¦ê°• ë¼ì´ë¸ŒëŸ¬ë¦¬ë¡œ, ì‹¤ì œ ë¬¸ì„œ ìŠ¤ìº”ì´ë‚˜ ì´¬ì˜ ì‹œ ë°œìƒí•˜ëŠ” ë‹¤ì–‘í•œ ì™œê³¡ì„ ì¬í˜„í•œë‹¤.

```python
from augraphy import *
import cv2

# Augraphy íŒŒì´í”„ë¼ì¸ ìƒì„±
def create_document_augmentation_pipeline():
    """ë¬¸ì„œ ì¦ê°• íŒŒì´í”„ë¼ì¸ ìƒì„±"""
    ink_phase = [
        InkBleed(p=0.7),
        Letterpress(p=0.5),
        LowInkPeriodicLines(p=0.3),
    ]
    
    paper_phase = [
        PaperFactory(p=0.5),
        ColorPaper(p=0.3),
        WaterMark(p=0.2),
        Folding(p=0.3),
    ]
    
    post_phase = [
        LightingGradient(p=0.5),
        DirtyRollers(p=0.3),
        SubtleNoise(p=0.5),
        Jpeg(p=0.3),
        Markup(p=0.2),
    ]
    
    pipeline = AugraphyPipeline(ink_phase, paper_phase, post_phase)
    return pipeline

# ë¬¸ì„œ ì´ë¯¸ì§€ ì¦ê°• í•¨ìˆ˜
def augment_document_image(image_path):
    """ë‹¨ì¼ ë¬¸ì„œ ì´ë¯¸ì§€ ì¦ê°•"""
    pipeline = create_document_augmentation_pipeline()
    
    image = cv2.imread(str(image_path))
    if image is None:
        return None
    
    # AugraphyëŠ” ì´ë¯¸ì§€ë¥¼ ì§ì ‘ ë³€í™˜
    augmented = pipeline(image)
    return augmented

# ë©€í‹°í”„ë¡œì„¸ì‹±ê³¼ ê²°í•©
def multiprocess_document_augmentation(image_paths, num_workers=None):
    """ë¬¸ì„œ ì´ë¯¸ì§€ ë©€í‹°í”„ë¡œì„¸ì‹± ì¦ê°•"""
    if num_workers is None:
        num_workers = mp.cpu_count()
    
    with ProcessPoolExecutor(max_workers=num_workers) as executor:
        futures = {executor.submit(augment_document_image, path): path 
                  for path in image_paths}
        
        results = {}
        for future in as_completed(futures):
            path = futures[future]
            try:
                augmented = future.result()
                if augmented is not None:
                    results[path] = augmented
            except Exception as e:
                print(f"Error processing {path}: {e}")
    
    return results

# ë¬¸ì„œ ì´ë¯¸ì§€ 1000ì¥ ì²˜ë¦¬
# ì¶œë ¥: ì²˜ë¦¬ ì‹œê°„: 45.23ì´ˆ (ë¬¸ì„œ íŠ¹í™” ì¦ê°•ì€ ë” ë³µì¡í•˜ì—¬ ì‹œê°„ì´ ë” ê±¸ë¦¼)
```

[ì‹œê°ì  í‘œí˜„ ë„£ê¸°: Augraphyë¡œ ì¦ê°•ëœ ë¬¸ì„œ ì´ë¯¸ì§€ ì˜ˆì‹œë“¤]

## ğŸ”€ Albumentations + Augraphy í•˜ì´ë¸Œë¦¬ë“œ íŒŒì´í”„ë¼ì¸

### ë‘ ë¼ì´ë¸ŒëŸ¬ë¦¬ì˜ ì¥ì  ê²°í•©

ì¼ë°˜ì ì¸ ì´ë¯¸ì§€ ë³€í™˜(Albumentations)ê³¼ ë¬¸ì„œ íŠ¹í™” ë³€í™˜(Augraphy)ì„ ê²°í•©í•˜ë©´ ë” ë‹¤ì–‘í•œ ì¦ê°•ì´ ê°€ëŠ¥í•˜ë‹¤.

```python
class HybridAugmentationPipeline:
    """Albumentationsì™€ Augraphyë¥¼ ê²°í•©í•œ íŒŒì´í”„ë¼ì¸"""
    
    def __init__(self, use_document_aug=True, use_general_aug=True):
        self.use_document_aug = use_document_aug
        self.use_general_aug = use_general_aug
        
        # Albumentations ë³€í™˜
        self.general_transform = A.Compose([
            A.RandomRotate90(p=0.5),
            A.Perspective(p=0.3),
            A.RandomBrightnessContrast(p=0.5),
            A.GaussNoise(p=0.3),
            A.RandomShadow(p=0.2),
        ])
        
        # Augraphy íŒŒì´í”„ë¼ì¸
        if self.use_document_aug:
            self.doc_pipeline = self._create_doc_pipeline()
    
    def _create_doc_pipeline(self):
        """ë¬¸ì„œ ì¦ê°• íŒŒì´í”„ë¼ì¸ ìƒì„±"""
        ink_phase = [
            InkBleed(p=0.5),
            Faxify(p=0.3),
        ]
        
        paper_phase = [
            PaperFactory(p=0.5),
            CreasesAndFolds(p=0.3),
        ]
        
        post_phase = [
            Scanner(p=0.3),
            BadPhotoCopy(p=0.2),
        ]
        
        return AugraphyPipeline(ink_phase, paper_phase, post_phase)
    
    def __call__(self, image):
        """ì´ë¯¸ì§€ì— í•˜ì´ë¸Œë¦¬ë“œ ì¦ê°• ì ìš©"""
        # ë¨¼ì € ì¼ë°˜ì ì¸ ì¦ê°• ì ìš©
        if self.use_general_aug:
            image = self.general_transform(image=image)['image']
        
        # ë¬¸ì„œ íŠ¹í™” ì¦ê°• ì ìš©
        if self.use_document_aug:
            image = self.doc_pipeline(image)
        
        return image

# í•˜ì´ë¸Œë¦¬ë“œ ì¦ê°• í•¨ìˆ˜
def hybrid_augment_image(args):
    """í•˜ì´ë¸Œë¦¬ë“œ íŒŒì´í”„ë¼ì¸ì„ ì‚¬ìš©í•œ ì´ë¯¸ì§€ ì¦ê°•"""
    image_path, use_doc, use_general = args
    
    pipeline = HybridAugmentationPipeline(
        use_document_aug=use_doc,
        use_general_aug=use_general
    )
    
    image = cv2.imread(str(image_path))
    if image is None:
        return None, image_path
    
    augmented = pipeline(image)
    return augmented, image_path

# ë©€í‹°í”„ë¡œì„¸ì‹± í•˜ì´ë¸Œë¦¬ë“œ ì¦ê°•
def multiprocess_hybrid_augmentation(image_paths, use_doc=True, 
                                   use_general=True, num_workers=None):
    """í•˜ì´ë¸Œë¦¬ë“œ íŒŒì´í”„ë¼ì¸ ë©€í‹°í”„ë¡œì„¸ì‹±"""
    if num_workers is None:
        num_workers = mp.cpu_count()
    
    args = [(path, use_doc, use_general) for path in image_paths]
    
    results = {}
    with mp.Pool(processes=num_workers) as pool:
        for augmented, path in tqdm(pool.imap(hybrid_augment_image, args), 
                                   total=len(args), desc="í•˜ì´ë¸Œë¦¬ë“œ ì¦ê°•"):
            if augmented is not None:
                results[path] = augmented
    
    return results

# ì‚¬ìš© ì˜ˆì‹œ
results = multiprocess_hybrid_augmentation(image_paths)
# ì¶œë ¥: í•˜ì´ë¸Œë¦¬ë“œ ì¦ê°•: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:32<00:00, 31.25it/s]
```

## âš¡ ì„±ëŠ¥ ìµœì í™” ì „ëµ

### ìµœì ì˜ ì›Œì»¤ ìˆ˜ ì°¾ê¸°

CPU ì½”ì–´ ìˆ˜ì™€ ì´ë¯¸ì§€ í¬ê¸°, ì¦ê°• ë³µì¡ë„ì— ë”°ë¼ ìµœì ì˜ ì›Œì»¤ ìˆ˜ê°€ ë‹¬ë¼ì§„ë‹¤.

```python
import psutil
import matplotlib.pyplot as plt

def benchmark_worker_counts(image_paths, transform_config, max_workers_range=None):
    """ë‹¤ì–‘í•œ ì›Œì»¤ ìˆ˜ë¡œ ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬"""
    if max_workers_range is None:
        cpu_count = psutil.cpu_count(logical=True)
        max_workers_range = range(1, cpu_count + 1)
    
    times = []
    worker_counts = []
    
    for num_workers in max_workers_range:
        start_time = time.time()
        
        # ìƒ˜í”Œ ì‹¤í–‰
        sample_paths = image_paths[:100]  # ë²¤ì¹˜ë§ˆí¬ìš© ìƒ˜í”Œ
        with ProcessPoolExecutor(max_workers=num_workers) as executor:
            futures = [executor.submit(augment_image, path, transform_config) 
                      for path in sample_paths]
            for future in as_completed(futures):
                _ = future.result()
        
        elapsed_time = time.time() - start_time
        times.append(elapsed_time)
        worker_counts.append(num_workers)
        
        print(f"Workers: {num_workers}, Time: {elapsed_time:.2f}s")
    
    # ì‹œê°í™”
    plt.figure(figsize=(10, 6))
    plt.plot(worker_counts, times, 'b-o')
    plt.xlabel('Number of Workers')
    plt.ylabel('Time (seconds)')
    plt.title('Processing Time vs Number of Workers')
    plt.grid(True)
    plt.show()
    
    # ìµœì  ì›Œì»¤ ìˆ˜ ë°˜í™˜
    optimal_workers = worker_counts[times.index(min(times))]
    print(f"\nìµœì  ì›Œì»¤ ìˆ˜: {optimal_workers}")
    return optimal_workers

# CPU ì½”ì–´ê°€ 8ê°œì¸ ê²½ìš° ì¼ë°˜ì ìœ¼ë¡œ 6-8ê°œì˜ ì›Œì»¤ê°€ ìµœì 
# ì¶œë ¥: ìµœì  ì›Œì»¤ ìˆ˜: 7
```

### ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ëª¨ë‹ˆí„°ë§

ë©€í‹°í”„ë¡œì„¸ì‹± ì‹œ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ì„ ëª¨ë‹ˆí„°ë§í•˜ì—¬ ì‹œìŠ¤í…œ ë¦¬ì†ŒìŠ¤ë¥¼ íš¨ìœ¨ì ìœ¼ë¡œ ê´€ë¦¬í•œë‹¤.

```python
def monitor_memory_usage():
    """ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ëª¨ë‹ˆí„°ë§ ë°ì½”ë ˆì´í„°"""
    def decorator(func):
        def wrapper(*args, **kwargs):
            # ì‹œì‘ ì „ ë©”ëª¨ë¦¬
            process = psutil.Process()
            start_memory = process.memory_info().rss / 1024 / 1024  # MB
            
            # í•¨ìˆ˜ ì‹¤í–‰
            result = func(*args, **kwargs)
            
            # ì¢…ë£Œ í›„ ë©”ëª¨ë¦¬
            end_memory = process.memory_info().rss / 1024 / 1024  # MB
            
            print(f"ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰: {start_memory:.2f}MB â†’ {end_memory:.2f}MB")
            print(f"ì¦ê°€ëŸ‰: {end_memory - start_memory:.2f}MB")
            
            return result
        return wrapper
    return decorator

@monitor_memory_usage()
def memory_efficient_augmentation(image_paths, transform_config, batch_size=50):
    """ë©”ëª¨ë¦¬ íš¨ìœ¨ì ì¸ ë°°ì¹˜ ì²˜ë¦¬"""
    all_results = {}
    
    # ë°°ì¹˜ ë‹¨ìœ„ë¡œ ì²˜ë¦¬í•˜ì—¬ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ì œí•œ
    for i in range(0, len(image_paths), batch_size):
        batch_paths = image_paths[i:i + batch_size]
        batch_results = multiprocess_augmentation_futures(
            batch_paths, transform_config
        )
        all_results.update(batch_results[0])
        
        # ê°€ë¹„ì§€ ì»¬ë ‰ì…˜ ê°•ì œ ì‹¤í–‰
        import gc
        gc.collect()
    
    return all_results

# ì¶œë ¥: ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰: 245.32MB â†’ 412.45MB
# ì¦ê°€ëŸ‰: 167.13MB
```

## ğŸ¯ ì‹¤ì „ í™œìš© ì˜ˆì œ

### OCR ì „ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸

ë¬¸ì„œ OCRì„ ìœ„í•œ ì „ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸ êµ¬í˜„ ì˜ˆì œì´ë‹¤.

```python
class OCRPreprocessingPipeline:
    """OCRì„ ìœ„í•œ ë¬¸ì„œ ì „ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸"""
    
    def __init__(self, enhance_quality=True):
        self.enhance_quality = enhance_quality
        
        # OCR ì •í™•ë„ í–¥ìƒì„ ìœ„í•œ ì „ì²˜ë¦¬
        self.ocr_transform = A.Compose([
            A.Rotate(limit=5, p=0.5),  # ì•½ê°„ì˜ íšŒì „ ë³´ì •
            A.Perspective(scale=(0.02, 0.05), p=0.3),
            A.CLAHE(clip_limit=2.0, p=0.5),  # ëŒ€ë¹„ í–¥ìƒ
            A.Sharpen(p=0.3),  # ì„ ëª…ë„ í–¥ìƒ
        ])
        
        # ë¬¸ì„œ ë…¸ì´ì¦ˆ ì‹œë®¬ë ˆì´ì…˜
        self.noise_pipeline = create_document_augmentation_pipeline()
    
    def preprocess_for_ocr(self, image):
        """OCRì„ ìœ„í•œ ì´ë¯¸ì§€ ì „ì²˜ë¦¬"""
        # ê·¸ë ˆì´ìŠ¤ì¼€ì¼ ë³€í™˜
        if len(image.shape) == 3:
            gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
        else:
            gray = image
        
        # ì´ì§„í™”
        _, binary = cv2.threshold(gray, 0, 255, 
                                 cv2.THRESH_BINARY + cv2.THRESH_OTSU)
        
        # ë…¸ì´ì¦ˆ ì œê±°
        denoised = cv2.fastNlMeansDenoising(binary)
        
        return denoised
    
    def augment_and_preprocess(self, image):
        """ì¦ê°• í›„ OCR ì „ì²˜ë¦¬"""
        # 1. ë°ì´í„° ì¦ê°• (í•™ìŠµìš©)
        augmented = self.ocr_transform(image=image)['image']
        augmented = self.noise_pipeline(augmented)
        
        # 2. OCR ì „ì²˜ë¦¬
        if self.enhance_quality:
            processed = self.preprocess_for_ocr(augmented)
        else:
            processed = augmented
        
        return processed

# OCR ë°ì´í„°ì…‹ ì¦ê°•
def prepare_ocr_dataset(image_paths, output_dir, num_augmentations=5):
    """OCR í•™ìŠµì„ ìœ„í•œ ë°ì´í„°ì…‹ ì¤€ë¹„"""
    pipeline = OCRPreprocessingPipeline()
    output_dir = Path(output_dir)
    output_dir.mkdir(exist_ok=True)
    
    def process_single_image(args):
        img_path, aug_idx = args
        image = cv2.imread(str(img_path))
        if image is None:
            return None
        
        # ì¦ê°• ë° ì „ì²˜ë¦¬
        processed = pipeline.augment_and_preprocess(image)
        
        # ì €ì¥
        stem = img_path.stem
        output_path = output_dir / f"{stem}_aug_{aug_idx}.png"
        cv2.imwrite(str(output_path), processed)
        
        return output_path
    
    # ê° ì´ë¯¸ì§€ë§ˆë‹¤ ì—¬ëŸ¬ ì¦ê°• ë²„ì „ ìƒì„±
    args_list = [(path, i) 
                 for path in image_paths 
                 for i in range(num_augmentations)]
    
    with mp.Pool() as pool:
        results = list(tqdm(
            pool.imap(process_single_image, args_list),
            total=len(args_list),
            desc="OCR ë°ì´í„°ì…‹ ìƒì„±"
        ))
    
    successful = [r for r in results if r is not None]
    print(f"ìƒì„± ì™„ë£Œ: {len(successful)}ê°œ ì´ë¯¸ì§€")
    
    return successful

# ì‚¬ìš© ì˜ˆì‹œ
augmented_paths = prepare_ocr_dataset(
    image_paths[:100], 
    "./ocr_dataset",
    num_augmentations=5
)
# ì¶œë ¥: OCR ë°ì´í„°ì…‹ ìƒì„±: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 500/500 [00:23<00:00, 21.74it/s]
# ìƒì„± ì™„ë£Œ: 500ê°œ ì´ë¯¸ì§€
```

### ì‹¤ì‹œê°„ ì¦ê°• ì„œë²„ êµ¬í˜„

ì›¹ ì„œë¹„ìŠ¤ì—ì„œ ì‹¤ì‹œê°„ìœ¼ë¡œ ì´ë¯¸ì§€ ì¦ê°•ì„ ì œê³µí•˜ëŠ” ì„œë²„ ì˜ˆì œì´ë‹¤.

```python
from multiprocessing import Queue, Process
import asyncio
from typing import Dict, List

class AugmentationServer:
    """ë¹„ë™ê¸° ì´ë¯¸ì§€ ì¦ê°• ì„œë²„"""
    
    def __init__(self, num_workers=4):
        self.num_workers = num_workers
        self.task_queue = Queue()
        self.result_queue = Queue()
        self.workers = []
        self.running = False
    
    def worker_process(self):
        """ì›Œì»¤ í”„ë¡œì„¸ìŠ¤ í•¨ìˆ˜"""
        # ê° ì›Œì»¤ë§ˆë‹¤ íŒŒì´í”„ë¼ì¸ ì´ˆê¸°í™”
        transform = A.Compose([
            A.RandomRotate90(),
            A.Flip(),
            A.RandomBrightnessContrast(p=0.5),
        ])
        
        while self.running:
            try:
                # íƒœìŠ¤í¬ ê°€ì ¸ì˜¤ê¸° (1ì´ˆ íƒ€ì„ì•„ì›ƒ)
                task = self.task_queue.get(timeout=1)
                if task is None:  # ì¢…ë£Œ ì‹ í˜¸
                    break
                
                task_id, image = task
                
                # ì¦ê°• ìˆ˜í–‰
                augmented = transform(image=image)['image']
                
                # ê²°ê³¼ ì „ì†¡
                self.result_queue.put((task_id, augmented))
                
            except:
                continue
    
    def start(self):
        """ì„œë²„ ì‹œì‘"""
        self.running = True
        
        # ì›Œì»¤ í”„ë¡œì„¸ìŠ¤ ìƒì„±
        for _ in range(self.num_workers):
            p = Process(target=self.worker_process)
            p.start()
            self.workers.append(p)
        
        print(f"ì¦ê°• ì„œë²„ ì‹œì‘: {self.num_workers}ê°œ ì›Œì»¤")
    
    def stop(self):
        """ì„œë²„ ì¤‘ì§€"""
        self.running = False
        
        # ì¢…ë£Œ ì‹ í˜¸ ì „ì†¡
        for _ in self.workers:
            self.task_queue.put(None)
        
        # ì›Œì»¤ ì¢…ë£Œ ëŒ€ê¸°
        for p in self.workers:
            p.join()
        
        print("ì¦ê°• ì„œë²„ ì¤‘ì§€")
    
    async def augment_async(self, task_id: str, image: np.ndarray):
        """ë¹„ë™ê¸° ì¦ê°• ìš”ì²­"""
        # íƒœìŠ¤í¬ íì— ì¶”ê°€
        self.task_queue.put((task_id, image))
        
        # ê²°ê³¼ ëŒ€ê¸° (í´ë§ ë°©ì‹)
        while True:
            try:
                result_id, result_image = self.result_queue.get_nowait()
                if result_id == task_id:
                    return result_image
                else:
                    # ë‹¤ë¥¸ íƒœìŠ¤í¬ì˜ ê²°ê³¼ëŠ” ë‹¤ì‹œ íì— ë„£ê¸°
                    self.result_queue.put((result_id, result_image))
            except:
                await asyncio.sleep(0.01)

# ì„œë²„ ì‚¬ìš© ì˜ˆì‹œ
async def main():
    server = AugmentationServer(num_workers=4)
    server.start()
    
    try:
        # ì—¬ëŸ¬ ì´ë¯¸ì§€ ë™ì‹œ ì²˜ë¦¬
        tasks = []
        for i in range(10):
            image = cv2.imread(f"image_{i}.jpg")
            task = server.augment_async(f"task_{i}", image)
            tasks.append(task)
        
        # ëª¨ë“  ê²°ê³¼ ëŒ€ê¸°
        results = await asyncio.gather(*tasks)
        print(f"ì²˜ë¦¬ ì™„ë£Œ: {len(results)}ê°œ ì´ë¯¸ì§€")
        
    finally:
        server.stop()

# asyncio.run(main())
```

## ğŸ” ì¼ë°˜ì ì¸ ë¬¸ì œ í•´ê²°

### Pickle ì—ëŸ¬ í•´ê²°

ë©€í‹°í”„ë¡œì„¸ì‹± ì‹œ ìì£¼ ë°œìƒí•˜ëŠ” pickle ì—ëŸ¬ë¥¼ í•´ê²°í•˜ëŠ” ë°©ë²•ì´ë‹¤.

```python
# ë¬¸ì œ: Lambda í•¨ìˆ˜ëŠ” pickleí•  ìˆ˜ ì—†ìŒ
# transform = A.Compose([
#     A.Lambda(lambda x, **kwargs: custom_function(x))  # ì—ëŸ¬ ë°œìƒ!
# ])

# í•´ê²°ì±… 1: ì¼ë°˜ í•¨ìˆ˜ë¡œ ì •ì˜
def custom_transform(image, **kwargs):
    return custom_function(image)

transform = A.Compose([
    A.Lambda(custom_transform)
])

# í•´ê²°ì±… 2: ì„¤ì •ì„ ì „ë‹¬í•˜ê³  í”„ë¡œì„¸ìŠ¤ì—ì„œ ì¬ìƒì„±
def worker_with_config(args):
    image_path, config_dict = args
    
    # í”„ë¡œì„¸ìŠ¤ ë‚´ì—ì„œ transform ìƒì„±
    transforms = []
    for t_config in config_dict['transforms']:
        transform_class = getattr(A, t_config['name'])
        transform = transform_class(**t_config['params'])
        transforms.append(transform)
    
    pipeline = A.Compose(transforms)
    # ... ì²˜ë¦¬ ë¡œì§
```

### ë©”ëª¨ë¦¬ ëˆ„ìˆ˜ ë°©ì§€

ì¥ì‹œê°„ ì‹¤í–‰ ì‹œ ë©”ëª¨ë¦¬ ëˆ„ìˆ˜ë¥¼ ë°©ì§€í•˜ëŠ” ë°©ë²•ì´ë‹¤.

```python
import gc
import tracemalloc

def memory_safe_processing(image_paths, transform_config, 
                         batch_size=100, memory_limit_gb=4):
    """ë©”ëª¨ë¦¬ ì•ˆì „ ì²˜ë¦¬"""
    tracemalloc.start()
    
    results = {}
    
    for i in range(0, len(image_paths), batch_size):
        batch = image_paths[i:i + batch_size]
        
        # ë°°ì¹˜ ì²˜ë¦¬
        batch_results = multiprocess_augmentation_futures(batch, transform_config)
        results.update(batch_results[0])
        
        # ë©”ëª¨ë¦¬ ì²´í¬
        current, peak = tracemalloc.get_traced_memory()
        current_gb = current / 1024 / 1024 / 1024
        
        if current_gb > memory_limit_gb:
            print(f"ë©”ëª¨ë¦¬ í•œê³„ ë„ë‹¬: {current_gb:.2f}GB")
            gc.collect()  # ê°€ë¹„ì§€ ì»¬ë ‰ì…˜ ê°•ì œ ì‹¤í–‰
            
            # ì—¬ì „íˆ ë†’ìœ¼ë©´ ì¼ì‹œ ì¤‘ì§€
            if current_gb > memory_limit_gb * 0.8:
                time.sleep(1)
        
        print(f"ì§„í–‰ë¥ : {i + len(batch)}/{len(image_paths)}, "
              f"ë©”ëª¨ë¦¬: {current_gb:.2f}GB")
    
    tracemalloc.stop()
    return results
```

## ğŸ“Š ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬ ë° ëª¨ë²” ì‚¬ë¡€

### ìµœì¢… ì„±ëŠ¥ ë¹„êµ

ë‹¤ì–‘í•œ ë°©ë²•ì˜ ì„±ëŠ¥ì„ ì¢…í•©ì ìœ¼ë¡œ ë¹„êµí•œ ê²°ê³¼ì´ë‹¤.

```python
def comprehensive_benchmark(image_paths, transform_config):
    """ì¢…í•© ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬"""
    methods = {
        'ë‹¨ì¼ í”„ë¡œì„¸ìŠ¤': lambda: single_process_augmentation(
            image_paths, A.Compose(transform_config)
        ),
        'ProcessPoolExecutor': lambda: multiprocess_augmentation_futures(
            image_paths, transform_config
        ),
        'ì²­í¬ ê¸°ë°˜': lambda: multiprocess_augmentation_chunks(
            image_paths, transform_config
        ),
        'Pool with imap': lambda: multiprocess_with_progress(
            image_paths, transform_config
        ),
    }
    
    results = {}
    
    for method_name, method_func in methods.items():
        print(f"\n{method_name} í…ŒìŠ¤íŠ¸ ì¤‘...")
        start_time = time.time()
        
        _ = method_func()
        
        elapsed = time.time() - start_time
        results[method_name] = elapsed
        
        print(f"{method_name}: {elapsed:.2f}ì´ˆ")
    
    # ì†ë„ í–¥ìƒ ë¹„ìœ¨ ê³„ì‚°
    single_time = results['ë‹¨ì¼ í”„ë¡œì„¸ìŠ¤']
    
    print("\n=== ì†ë„ í–¥ìƒ ë¹„ìœ¨ ===")
    for method, elapsed in results.items():
        speedup = single_time / elapsed
        print(f"{method}: {speedup:.2f}x")
    
    return results

# 1000ê°œ ì´ë¯¸ì§€ë¡œ í…ŒìŠ¤íŠ¸
# ì¶œë ¥:
# === ì†ë„ í–¥ìƒ ë¹„ìœ¨ ===
# ë‹¨ì¼ í”„ë¡œì„¸ìŠ¤: 1.0x
# ProcessPoolExecutor: 4.2x
# ì²­í¬ ê¸°ë°˜: 4.8x
# Pool with imap: 4.5x
```

[ì‹œê°ì  í‘œí˜„ ë„£ê¸°: ê° ë°©ë²•ë³„ ì„±ëŠ¥ ë¹„êµ ë§‰ëŒ€ ê·¸ë˜í”„]

### ëª¨ë²” ì‚¬ë¡€ ì •ë¦¬

ë©€í‹°í”„ë¡œì„¸ì‹± ì´ë¯¸ì§€ ì¦ê°• ì‹œ ë”°ë¼ì•¼ í•  ëª¨ë²” ì‚¬ë¡€ì´ë‹¤.

- **ì ì ˆí•œ ì›Œì»¤ ìˆ˜ ì„ íƒ**: CPU ì½”ì–´ ìˆ˜ì˜ 75-100% ì‚¬ìš©
- **ì²­í¬ í¬ê¸° ìµœì í™”**: ì´ë¯¸ì§€ í¬ê¸°ì™€ ì¦ê°• ë³µì¡ë„ì— ë”°ë¼ ì¡°ì •
- **ë©”ëª¨ë¦¬ ê´€ë¦¬**: ë°°ì¹˜ ì²˜ë¦¬ì™€ ê°€ë¹„ì§€ ì»¬ë ‰ì…˜ í™œìš©
- **ì—ëŸ¬ ì²˜ë¦¬**: ê°œë³„ ì´ë¯¸ì§€ ì‹¤íŒ¨ê°€ ì „ì²´ í”„ë¡œì„¸ìŠ¤ë¥¼ ì¤‘ë‹¨ì‹œí‚¤ì§€ ì•Šë„ë¡
- **ì§„í–‰ë¥  í‘œì‹œ**: ëŒ€ìš©ëŸ‰ ì²˜ë¦¬ ì‹œ ì‚¬ìš©ì ê²½í—˜ í–¥ìƒ

> ë©€í‹°í”„ë¡œì„¸ì‹±ì„ í†µí•œ ì´ë¯¸ì§€ ì¦ê°•ì€ ëŒ€ê·œëª¨ ë°ì´í„°ì…‹ ì²˜ë¦¬ì— í•„ìˆ˜ì ì¸ ê¸°ìˆ ì´ë‹¤. ì ì ˆí•œ ì„¤ì •ê³¼ ìµœì í™”ë¥¼ í†µí•´ ì²˜ë¦¬ ì‹œê°„ì„ íšê¸°ì ìœ¼ë¡œ ë‹¨ì¶•í•  ìˆ˜ ìˆìœ¼ë©°, ì´ëŠ” ëª¨ë¸ í•™ìŠµ íŒŒì´í”„ë¼ì¸ì˜ íš¨ìœ¨ì„±ì„ í¬ê²Œ í–¥ìƒì‹œí‚¨ë‹¤. {: .prompt-tip}