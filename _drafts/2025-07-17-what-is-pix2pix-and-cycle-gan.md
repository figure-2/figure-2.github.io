---
title: "ğŸ¨ Pix2Pixì™€ CycleGAN: ì¡°ê±´ë¶€ GANì„ í™œìš©í•œ ì´ë¯¸ì§€ ê°„ ë³€í™˜"
date: 2025-07-17 13:29:00 +0900
categories: 
tags:
  - ê¸‰ë°œì§„ê±°ë¶ì´
toc: true
comments: false
mermaid: true
math: true
---
## ğŸ“¦ ì‚¬ìš©í•˜ëŠ” python package

- torch==1.4.0+
- torchvision==0.5.0+
- matplotlib==3.3.0+
- PIL==7.2.0+
- numpy==1.19.0+
- os (ë‚´ì¥ ëª¨ë“ˆ)

## ğŸš€ TL;DR

- **Pix2Pix**ëŠ” **paired ë°ì´í„°**ë¥¼ í™œìš©í•œ ì¡°ê±´ë¶€ GANìœ¼ë¡œ, ì…ë ¥ ì´ë¯¸ì§€ë¥¼ ì¡°ê±´ìœ¼ë¡œ ë°›ì•„ ëŒ€ìƒ ë„ë©”ì¸ì˜ ì´ë¯¸ì§€ë¥¼ ìƒì„±í•œë‹¤
- **CycleGAN**ì€ **unpaired ë°ì´í„°**ë¡œë„ ì´ë¯¸ì§€ ë³€í™˜ì´ ê°€ëŠ¥í•˜ë©°, **cycle consistency loss**ë¥¼ í†µí•´ ë‘ ë„ë©”ì¸ ê°„ ì–‘ë°©í–¥ ë³€í™˜ì„ í•™ìŠµí•œë‹¤
- Pix2PixëŠ” **U-Net êµ¬ì¡°ì˜ ìƒì„±ì**ì™€ **PatchGAN íŒë³„ì**ë¥¼ ì‚¬ìš©í•˜ê³ , **GAN loss + L1 reconstruction loss**ë¡œ í•™ìŠµí•œë‹¤
- CycleGANì€ **ResNet ê¸°ë°˜ ìƒì„±ì 2ê°œ**ì™€ **íŒë³„ì 2ê°œ**ë¥¼ ì‚¬ìš©í•˜ë©°, **adversarial loss + cycle consistency loss**ë¡œ í•™ìŠµí•œë‹¤
- **ì‹¤ì œ ì‘ìš© ë¶„ì•¼**: ìŠ¤ì¼€ì¹˜â†’ì‚¬ì§„, í‘ë°±â†’ì»¬ëŸ¬, ë‚®â†’ë°¤, ë§â†’ì–¼ë£©ë§ ë“± ë‹¤ì–‘í•œ ì´ë¯¸ì§€ ìŠ¤íƒ€ì¼ ë³€í™˜ì— í™œìš©ëœë‹¤

## ğŸ““ ì‹¤ìŠµ Jupyter Notebook

- [Pix2Pix ê³µì‹ ì½”ë“œ](https://github.com/junyanz/pytorch-CycleGAN-and-pix2pix)
- [CycleGAN & Pix2Pix PyTorch êµ¬í˜„](https://github.com/junyanz/pytorch-CycleGAN-and-pix2pix)

## ğŸ¯ ì´ë¯¸ì§€ ê°„ ë³€í™˜(Image-to-Image Translation)ì´ë€?

ì´ë¯¸ì§€ ê°„ ë³€í™˜ì€ í•˜ë‚˜ì˜ ì´ë¯¸ì§€ ë„ë©”ì¸ì—ì„œ ë‹¤ë¥¸ ì´ë¯¸ì§€ ë„ë©”ì¸ìœ¼ë¡œ ì´ë¯¸ì§€ë¥¼ ë³€í™˜í•˜ëŠ” ê¸°ìˆ ì´ë‹¤. ì˜ˆë¥¼ ë“¤ì–´ ìŠ¤ì¼€ì¹˜ë¥¼ ì‹¤ì œ ì‚¬ì§„ìœ¼ë¡œ, í‘ë°± ì‚¬ì§„ì„ ì»¬ëŸ¬ ì‚¬ì§„ìœ¼ë¡œ, ë˜ëŠ” ê±´ë¬¼ì˜ ë¼ë²¨ë§µì„ ì‹¤ì œ ê±´ë¬¼ ì‚¬ì§„ìœ¼ë¡œ ë³€í™˜í•˜ëŠ” ê²ƒì´ ì´ì— í•´ë‹¹í•œë‹¤.

ì „í†µì ì¸ ì»´í“¨í„° ë¹„ì „ì—ì„œëŠ” ê° ë³€í™˜ ì‘ì—…ë§ˆë‹¤ ë³„ë„ì˜ ì•Œê³ ë¦¬ì¦˜ì„ ê°œë°œí•´ì•¼ í–ˆì§€ë§Œ, **ì¡°ê±´ë¶€ GAN(Conditional GAN)**ì˜ ë“±ì¥ìœ¼ë¡œ í•˜ë‚˜ì˜ í”„ë ˆì„ì›Œí¬ë¡œ ë‹¤ì–‘í•œ ë³€í™˜ ì‘ì—…ì„ ìˆ˜í–‰í•  ìˆ˜ ìˆê²Œ ë˜ì—ˆë‹¤.

> ì´ë¯¸ì§€ ê°„ ë³€í™˜ì€ **ì¡°ê±´ë¶€ ìƒì„± ëª¨ë¸ë§**ì˜ ëŒ€í‘œì ì¸ ì‘ìš© ì‚¬ë¡€ë¡œ, ì…ë ¥ ì´ë¯¸ì§€ë¥¼ ì¡°ê±´ìœ¼ë¡œ í™œìš©í•˜ì—¬ ì›í•˜ëŠ” ìŠ¤íƒ€ì¼ì´ë‚˜ ë„ë©”ì¸ì˜ ì´ë¯¸ì§€ë¥¼ ìƒì„±í•˜ëŠ” ê¸°ìˆ ì´ë‹¤. {: .prompt-tip}

### ì£¼ìš” ì‘ìš© ë¶„ì•¼

- **ìŠ¤íƒ€ì¼ ë³€í™˜**: ì‚¬ì§„ì„ ê·¸ë¦¼ì²´ë¡œ, ê·¸ë¦¼ì„ ì‚¬ì§„ìœ¼ë¡œ
- **ì‹œë§¨í‹± ë¶„í• **: ë¼ë²¨ë§µì„ ì‹¤ì œ ì´ë¯¸ì§€ë¡œ
- **ì´ë¯¸ì§€ ë³µì›**: í‘ë°±ì„ ì»¬ëŸ¬ë¡œ, ì €í•´ìƒë„ë¥¼ ê³ í•´ìƒë„ë¡œ
- **ë„ë©”ì¸ ì ì‘**: ë‚® í’ê²½ì„ ë°¤ í’ê²½ìœ¼ë¡œ

## ğŸ¨ Pix2Pix: Paired Dataë¥¼ í™œìš©í•œ ì´ë¯¸ì§€ ë³€í™˜

Pix2PixëŠ” 2017ë…„ Isola et al.ì´ ì œì•ˆí•œ ì¡°ê±´ë¶€ GAN ê¸°ë°˜ì˜ ì´ë¯¸ì§€ ê°„ ë³€í™˜ ëª¨ë¸ì´ë‹¤. í•µì‹¬ ì•„ì´ë””ì–´ëŠ” **ì…ë ¥ ì´ë¯¸ì§€ì™€ ì¶œë ¥ ì´ë¯¸ì§€ì˜ ìŒ(pair)**ì´ ì¡´ì¬í•˜ëŠ” ë°ì´í„°ì…‹ì—ì„œ í•˜ë‚˜ì˜ í†µí•©ëœ í”„ë ˆì„ì›Œí¬ë¡œ ë‹¤ì–‘í•œ ì´ë¯¸ì§€ ë³€í™˜ ì‘ì—…ì„ ìˆ˜í–‰í•˜ëŠ” ê²ƒì´ë‹¤.

### ìˆ˜í•™ì /ì´ë¡ ì  í‘œí˜„

Pix2Pixì˜ ëª©ì í•¨ìˆ˜ëŠ” ì¡°ê±´ë¶€ GAN ì†ì‹¤ê³¼ L1 ì¬êµ¬ì„± ì†ì‹¤ì˜ ì¡°í•©ìœ¼ë¡œ êµ¬ì„±ëœë‹¤:

$$ \mathcal{L}_{total} = \mathcal{L}_{cGAN}(G, D) + \lambda \mathcal{L}_{L1}(G) $$

ì—¬ê¸°ì„œ ì¡°ê±´ë¶€ GAN ì†ì‹¤ì€:

$$ \mathcal{L}_{cGAN}(G, D) = \mathbb{E}_{x,y}[\log D(x, y)] + \mathbb{E}_{x}[\log(1 - D(x, G(x)))] $$

L1 ì¬êµ¬ì„± ì†ì‹¤ì€:

$$ \mathcal{L}_{L1}(G) = \mathbb{E}_{x,y}[||y - G(x)||_1] $$

- **G**: ìƒì„±ì (ì…ë ¥ ì´ë¯¸ì§€ xë¥¼ ë°›ì•„ ì¶œë ¥ ì´ë¯¸ì§€ ìƒì„±)
- **D**: íŒë³„ì (ì…ë ¥-ì¶œë ¥ ì´ë¯¸ì§€ ìŒì˜ ì§„ìœ„ íŒë³„)
- **Î»**: L1 ì†ì‹¤ì˜ ê°€ì¤‘ì¹˜ (ì¼ë°˜ì ìœ¼ë¡œ 100 ì‚¬ìš©)

### ì•„í‚¤í…ì²˜ êµ¬ì¡°

**ìƒì„±ì (U-Net)**

- ì¸ì½”ë”-ë””ì½”ë” êµ¬ì¡°ì— skip connection ì¶”ê°€
- ê³ í•´ìƒë„ ì„¸ë¶€ì‚¬í•­ ë³´ì¡´ì— íš¨ê³¼ì 
- ì…ë ¥ ì´ë¯¸ì§€ì˜ ê³µê°„ì  ì •ë³´ë¥¼ ìœ ì§€í•˜ë©´ì„œ ë³€í™˜ ìˆ˜í–‰

**íŒë³„ì (PatchGAN)**

- 70Ã—70 íŒ¨ì¹˜ ë‹¨ìœ„ë¡œ ì´ë¯¸ì§€ì˜ ì§„ìœ„ íŒë³„
- ì „ì²´ ì´ë¯¸ì§€ê°€ ì•„ë‹Œ ë¡œì»¬ íŒ¨ì¹˜ì˜ ì‚¬ì‹¤ì„±ì— ì§‘ì¤‘
- ê³ ì£¼íŒŒ ì„¸ë¶€ì‚¬í•­ê³¼ í…ìŠ¤ì²˜ í’ˆì§ˆ ê°œì„ 

[ì‹œê°ì  í‘œí˜„ ë„£ê¸° - Pix2Pix ì•„í‚¤í…ì²˜ ë‹¤ì´ì–´ê·¸ë¨]

### ì‹¤ì œ êµ¬í˜„ ì˜ˆì‹œ

```python
import torch
import torch.nn as nn
from torchvision import transforms
from PIL import Image

class Pix2PixModel:
    def __init__(self, direction='BtoA', lambda_L1=100.0):
        self.direction = direction
        self.lambda_L1 = lambda_L1
        
        # ë„¤íŠ¸ì›Œí¬ ì´ˆê¸°í™”
        self.netG = self._define_generator()
        self.netD = self._define_discriminator()
        
        # ì†ì‹¤ í•¨ìˆ˜
        self.criterionGAN = nn.BCEWithLogitsLoss()
        self.criterionL1 = nn.L1Loss()
        
        # ì˜µí‹°ë§ˆì´ì €
        self.optimizer_G = torch.optim.Adam(self.netG.parameters(), lr=0.0002, betas=(0.5, 0.999))
        self.optimizer_D = torch.optim.Adam(self.netD.parameters(), lr=0.0002, betas=(0.5, 0.999))
    
    def optimize_parameters(self, real_A, real_B):
        # Forward pass
        fake_B = self.netG(real_A)
        
        # íŒë³„ì ì—…ë°ì´íŠ¸
        self.optimizer_D.zero_grad()
        
        # Real ì´ë¯¸ì§€ ìŒ
        pred_real = self.netD(torch.cat([real_A, real_B], 1))
        loss_D_real = self.criterionGAN(pred_real, torch.ones_like(pred_real))
        
        # Fake ì´ë¯¸ì§€ ìŒ
        pred_fake = self.netD(torch.cat([real_A, fake_B.detach()], 1))
        loss_D_fake = self.criterionGAN(pred_fake, torch.zeros_like(pred_fake))
        
        loss_D = (loss_D_real + loss_D_fake) * 0.5
        loss_D.backward()
        self.optimizer_D.step()
        
        # ìƒì„±ì ì—…ë°ì´íŠ¸  
        self.optimizer_G.zero_grad()
        
        # GAN ì†ì‹¤
        pred_fake = self.netD(torch.cat([real_A, fake_B], 1))
        loss_G_GAN = self.criterionGAN(pred_fake, torch.ones_like(pred_fake))
        
        # L1 ì†ì‹¤
        loss_G_L1 = self.criterionL1(fake_B, real_B) * self.lambda_L1
        
        loss_G = loss_G_GAN + loss_G_L1
        loss_G.backward()
        self.optimizer_G.step()
        
        return {'loss_G_GAN': loss_G_GAN.item(), 
                'loss_G_L1': loss_G_L1.item(),
                'loss_D': loss_D.item()}

# ë°ì´í„° ì „ì²˜ë¦¬
transform = transforms.Compose([
    transforms.Resize((256, 256)),
    transforms.ToTensor(),
    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))
])

# í•™ìŠµ ì˜ˆì‹œ
model = Pix2PixModel()
for epoch in range(num_epochs):
    for i, (input_img, target_img) in enumerate(dataloader):
        losses = model.optimize_parameters(input_img, target_img)
        if i % 100 == 0:
            print(f"Epoch {epoch}, Step {i}: {losses}")
```

### ë°ì´í„°ì…‹ ì¤€ë¹„

Pix2PixëŠ” **paired ë°ì´í„°**ë¥¼ í•„ìš”ë¡œ í•œë‹¤. ì¼ë°˜ì ìœ¼ë¡œ í•˜ë‚˜ì˜ ì´ë¯¸ì§€ íŒŒì¼ì— ì…ë ¥ê³¼ ì¶œë ¥ì´ ê°€ë¡œë¡œ ì—°ê²°ë˜ì–´ ì €ì¥ëœë‹¤:

```python
class AlignedDataset:
    def __init__(self, dataroot, phase='train'):
        self.dataroot = dataroot
        self.dir_AB = os.path.join(dataroot, phase)
        self.AB_paths = sorted(self._make_dataset(self.dir_AB))
        
    def __getitem__(self, index):
        AB_path = self.AB_paths[index]
        AB = Image.open(AB_path).convert('RGB')
        
        # ì´ë¯¸ì§€ë¥¼ Aì™€ Bë¡œ ë¶„í• 
        w, h = AB.size
        w2 = int(w / 2)
        A = AB.crop((0, 0, w2, h))      # ì™¼ìª½ ì ˆë°˜
        B = AB.crop((w2, 0, w, h))      # ì˜¤ë¥¸ìª½ ì ˆë°˜
        
        # ë³€í™˜ ì ìš©
        A = self.transform(A)
        B = self.transform(B)
        
        return {'A': A, 'B': B, 'A_paths': AB_path}
```

## ğŸ”„ CycleGAN: Unpaired Dataë¥¼ í™œìš©í•œ ì´ë¯¸ì§€ ë³€í™˜

CycleGANì€ 2017ë…„ Zhu et al.ì´ ì œì•ˆí•œ ëª¨ë¸ë¡œ, **ìŒìœ¼ë¡œ ì´ë£¨ì–´ì§€ì§€ ì•Šì€(unpaired) ë°ì´í„°**ë¡œë„ ì´ë¯¸ì§€ ê°„ ë³€í™˜ì„ í•™ìŠµí•  ìˆ˜ ìˆë‹¤ëŠ” í˜ì‹ ì ì¸ ì•„ì´ë””ì–´ë¥¼ ì œì‹œí–ˆë‹¤.

### í•µì‹¬ ì•„ì´ë””ì–´: Cycle Consistency

CycleGANì˜ í•µì‹¬ì€ **cycle consistency**ë¼ëŠ” ê°œë…ì´ë‹¤. ì´ë¯¸ì§€ë¥¼ í•œ ë„ë©”ì¸ì—ì„œ ë‹¤ë¥¸ ë„ë©”ì¸ìœ¼ë¡œ ë³€í™˜í•œ í›„, ë‹¤ì‹œ ì›ë˜ ë„ë©”ì¸ìœ¼ë¡œ ë³€í™˜í–ˆì„ ë•Œ ì›ë³¸ê³¼ ë™ì¼í•´ì•¼ í•œë‹¤ëŠ” ì œì•½ ì¡°ê±´ì´ë‹¤.

> **Cycle Consistency**: X â†’ Y â†’ X' ì—ì„œ X'ê°€ ì›ë³¸ Xì™€ ë™ì¼í•´ì•¼ í•œë‹¤ëŠ” ì›ë¦¬ë¡œ, ì´ë¥¼ í†µí•´ unpaired ë°ì´í„°ë¡œë„ ì˜ë¯¸ ìˆëŠ” ë³€í™˜ì„ í•™ìŠµí•  ìˆ˜ ìˆë‹¤. {: .prompt-tip}

### ìˆ˜í•™ì /ì´ë¡ ì  í‘œí˜„

CycleGANì˜ ì „ì²´ ëª©ì í•¨ìˆ˜ëŠ” ë‹¤ìŒê³¼ ê°™ë‹¤:

$$ \mathcal{L}_{total} = \mathcal{L}_{GAN}(G, D_Y, X, Y) + \mathcal{L}_{GAN}(F, D_X, Y, X) + \lambda \mathcal{L}_{cyc}(G, F) $$

**Adversarial Loss**: $$ \mathcal{L}_{GAN}(G, D_Y, X, Y) = \mathbb{E}_{y \sim p_{data}(y)}[\log D_Y(y)] + \mathbb{E}_{x \sim p_{data}(x)}[\log(1 - D_Y(G(x)))] $$

**Cycle Consistency Loss**: $$ \mathcal{L}_{cyc}(G, F) = \mathbb{E}_{x \sim p_{data}(x)}[||F(G(x)) - x||_1] + \mathbb{E}_{y \sim p_{data}(y)}[||G(F(y)) - y||_1] $$

- **G**: X â†’ Y ë³€í™˜ ìƒì„±ì
- **F**: Y â†’ X ë³€í™˜ ìƒì„±ì
- **D_X, D_Y**: ê° ë„ë©”ì¸ì˜ íŒë³„ì
- **Î»**: cycle consistency loss ê°€ì¤‘ì¹˜

### ì•„í‚¤í…ì²˜ êµ¬ì¡°

CycleGANì€ **4ê°œì˜ ë„¤íŠ¸ì›Œí¬**ë¡œ êµ¬ì„±ëœë‹¤:

1. **Generator G** (X â†’ Y): ResNet-9 blocks ì‚¬ìš©
2. **Generator F** (Y â†’ X): ResNet-9 blocks ì‚¬ìš©
3. **Discriminator D_X**: X ë„ë©”ì¸ ì´ë¯¸ì§€ íŒë³„
4. **Discriminator D_Y**: Y ë„ë©”ì¸ ì´ë¯¸ì§€ íŒë³„

[ì‹œê°ì  í‘œí˜„ ë„£ê¸° - CycleGAN ì•„í‚¤í…ì²˜ ë‹¤ì´ì–´ê·¸ë¨]

### ì‹¤ì œ êµ¬í˜„ ì˜ˆì‹œ

```python
class CycleGANModel:
    def __init__(self):
        # 4ê°œ ë„¤íŠ¸ì›Œí¬ ì´ˆê¸°í™”
        self.netG_A = self._define_generator()  # A â†’ B
        self.netG_B = self._define_generator()  # B â†’ A
        self.netD_A = self._define_discriminator()
        self.netD_B = self._define_discriminator()
        
        # ì†ì‹¤ í•¨ìˆ˜ (LSE GAN ì‚¬ìš©)
        self.criterionGAN = nn.MSELoss()
        self.criterionCycle = nn.L1Loss()
        
        # ì˜µí‹°ë§ˆì´ì €
        self.optimizer_G = torch.optim.Adam(
            list(self.netG_A.parameters()) + list(self.netG_B.parameters()),
            lr=0.0002, betas=(0.5, 0.999))
        self.optimizer_D = torch.optim.Adam(
            list(self.netD_A.parameters()) + list(self.netD_B.parameters()),
            lr=0.0002, betas=(0.5, 0.999))
        
        # ì´ì „ ì´ë¯¸ì§€ ì €ì¥ìš© í’€
        self.fake_A_pool = ImagePool(50)
        self.fake_B_pool = ImagePool(50)
    
    def forward(self, real_A, real_B):
        # Forward cycle: A â†’ B â†’ A
        self.fake_B = self.netG_A(real_A)
        self.rec_A = self.netG_B(self.fake_B)
        
        # Backward cycle: B â†’ A â†’ B  
        self.fake_A = self.netG_B(real_B)
        self.rec_B = self.netG_A(self.fake_A)
    
    def optimize_parameters(self, real_A, real_B):
        # Forward pass
        self.forward(real_A, real_B)
        
        # ìƒì„±ì ì—…ë°ì´íŠ¸
        self.optimizer_G.zero_grad()
        
        # GAN ì†ì‹¤
        loss_G_A = self.criterionGAN(self.netD_B(self.fake_B), 
                                    torch.ones_like(self.netD_B(self.fake_B)))
        loss_G_B = self.criterionGAN(self.netD_A(self.fake_A),
                                    torch.ones_like(self.netD_A(self.fake_A)))
        
        # Cycle consistency ì†ì‹¤
        loss_cycle_A = self.criterionCycle(self.rec_A, real_A) * 10.0
        loss_cycle_B = self.criterionCycle(self.rec_B, real_B) * 10.0
        
        loss_G = loss_G_A + loss_G_B + loss_cycle_A + loss_cycle_B
        loss_G.backward()
        self.optimizer_G.step()
        
        # íŒë³„ì ì—…ë°ì´íŠ¸
        self.optimizer_D.zero_grad()
        
        # íŒë³„ì A
        pred_real_A = self.netD_A(real_A)
        loss_D_real_A = self.criterionGAN(pred_real_A, torch.ones_like(pred_real_A))
        
        fake_A = self.fake_A_pool.query(self.fake_A)
        pred_fake_A = self.netD_A(fake_A.detach())
        loss_D_fake_A = self.criterionGAN(pred_fake_A, torch.zeros_like(pred_fake_A))
        
        loss_D_A = (loss_D_real_A + loss_D_fake_A) * 0.5
        
        # íŒë³„ì B (ë™ì¼í•œ ë°©ì‹)
        # ... íŒë³„ì B ì½”ë“œ ...
        
        loss_D = loss_D_A + loss_D_B
        loss_D.backward()
        self.optimizer_D.step()
```

### Image Pool ê¸°ë²•

CycleGANì—ì„œëŠ” **Image Pool**ì´ë¼ëŠ” ì¤‘ìš”í•œ ê¸°ë²•ì„ ì‚¬ìš©í•œë‹¤:

```python
class ImagePool:
    def __init__(self, pool_size=50):
        self.pool_size = pool_size
        self.num_imgs = 0
        self.images = []
    
    def query(self, images):
        if self.pool_size == 0:
            return images
        
        return_images = []
        for image in images:
            if self.num_imgs < self.pool_size:
                self.num_imgs += 1
                self.images.append(image)
                return_images.append(image)
            else:
                p = random.uniform(0, 1)
                if p > 0.5:  # 50% í™•ë¥ ë¡œ í’€ì—ì„œ ì„ íƒ
                    random_id = random.randint(0, self.pool_size - 1)
                    tmp = self.images[random_id].clone()
                    self.images[random_id] = image
                    return_images.append(tmp)
                else:
                    return_images.append(image)
        
        return torch.cat(return_images, 0)
```

> Image Poolì€ ê³¼ê±°ì— ìƒì„±ëœ ì´ë¯¸ì§€ë“¤ì„ ì €ì¥í•´ ë‘ì—ˆë‹¤ê°€ íŒë³„ì í•™ìŠµì— í™œìš©í•˜ëŠ” ê¸°ë²•ìœ¼ë¡œ, **íŒë³„ìê°€ ê³¼ê±°ì˜ ì‹¤ìˆ˜ë¥¼ ìŠì§€ ì•Šë„ë¡** ë„ì™€ì¤€ë‹¤. {: .prompt-tip}

## ğŸ” Pix2Pix vs CycleGAN ë¹„êµ

|íŠ¹ì§•|Pix2Pix|CycleGAN|
|---|---|---|
|**ë°ì´í„° ìš”êµ¬ì‚¬í•­**|Paired ë°ì´í„° í•„ìš”|Unpaired ë°ì´í„° ê°€ëŠ¥|
|**ë„¤íŠ¸ì›Œí¬ ìˆ˜**|2ê°œ (G, D)|4ê°œ (G_A, G_B, D_A, D_B)|
|**ì£¼ìš” ì†ì‹¤**|GAN Loss + L1 Loss|GAN Loss + Cycle Consistency|
|**ìƒì„±ì êµ¬ì¡°**|U-Net|ResNet with skip connections|
|**í•™ìŠµ ì•ˆì •ì„±**|ìƒëŒ€ì ìœ¼ë¡œ ì•ˆì •|ë” ë³µì¡í•œ í•™ìŠµ ê³¼ì •|
|**ì ìš© ë¶„ì•¼**|êµ¬ì¡°ì  ë³€í™˜ (ìŠ¤ì¼€ì¹˜â†’ì‚¬ì§„)|ìŠ¤íƒ€ì¼ ë³€í™˜ (ë§â†’ì–¼ë£©ë§)|

## ğŸ¯ ì‹¤ì œ í™œìš© ì‚¬ë¡€

### Pix2Pix í™œìš© ì‚¬ë¡€

- **ê±´ì¶•/ë„ì‹œê³„íš**: ê±´ë¬¼ ë¼ë²¨ë§µ â†’ ì‹¤ì œ ê±´ë¬¼ ì‚¬ì§„
- **ì˜ë£Œ ì˜ìƒ**: í•´ë¶€í•™ì  êµ¬ì¡° â†’ MRI/CT ì´ë¯¸ì§€
- **ë””ìì¸ ë„êµ¬**: ìŠ¤ì¼€ì¹˜ â†’ ì œí’ˆ ë Œë”ë§
- **ê²Œì„ ê°œë°œ**: 2D ë§µ â†’ 3D í™˜ê²½

### CycleGAN í™œìš© ì‚¬ë¡€

- **ì˜ˆìˆ /ì°½ì‘**: ì‚¬ì§„ â†’ ê·¸ë¦¼ì²´ ë³€í™˜ (ëª¨ë„¤, ë°˜ ê³ í ìŠ¤íƒ€ì¼)
- **ê³„ì ˆ ë³€í™˜**: ì—¬ë¦„ í’ê²½ â†’ ê²¨ìš¸ í’ê²½
- **ë™ë¬¼ ë³€í™˜**: ë§ â†’ ì–¼ë£©ë§
- **ìŠ¤íƒ€ì¼ ë³€í™˜**: ë‚® â†’ ë°¤, ë§‘ì€ ë‚ ì”¨ â†’ ë¹„ ì˜¤ëŠ” ë‚ ì”¨

## âš ï¸ í•œê³„ì ê³¼ ê°œì„  ë°©í–¥

### ê³µí†µ í•œê³„ì 

- **ëª¨ë“œ ë¶•ê´´(Mode Collapse)**: ë‹¤ì–‘ì„± ë¶€ì¡± ë¬¸ì œ
- **ê³„ì‚° ë¹„ìš©**: ë†’ì€ ë©”ëª¨ë¦¬ì™€ ì—°ì‚° ìš”êµ¬ëŸ‰
- **ë¶ˆì•ˆì •í•œ í•™ìŠµ**: ìƒì„±ìì™€ íŒë³„ì ê· í˜• ë§ì¶”ê¸° ì–´ë ¤ì›€

### ìµœì‹  ê°œì„  ê¸°ë²•

```python
# Spectral Normalizationìœ¼ë¡œ í•™ìŠµ ì•ˆì •í™”
import torch.nn.utils.spectral_norm as spectral_norm

class StabilizedDiscriminator(nn.Module):
    def __init__(self):
        super().__init__()
        self.conv1 = spectral_norm(nn.Conv2d(3, 64, 4, 2, 1))
        self.conv2 = spectral_norm(nn.Conv2d(64, 128, 4, 2, 1))
        # ... ì¶”ê°€ ë ˆì´ì–´

# Progressive Growing
class ProgressiveGenerator(nn.Module):
    def __init__(self):
        super().__init__()
        self.alpha = 1.0  # fade-in íŒŒë¼ë¯¸í„°
        # ì ì§„ì ìœ¼ë¡œ í•´ìƒë„ ì¦ê°€
```

## ğŸš€ ìµœì‹  ë°œì „ ë™í–¥

### ìµœì‹  ì—°êµ¬ ë°©í–¥

- **Few-shot í•™ìŠµ**: ì ì€ ë°ì´í„°ë¡œ íš¨ê³¼ì ì¸ ë³€í™˜
- **ë‹¤ì¤‘ ë„ë©”ì¸ ë³€í™˜**: StarGAN, MUNIT ë“±
- **ê³ í•´ìƒë„ ë³€í™˜**: SPADE, GauGAN ë“±
- **ì‹¤ì‹œê°„ ë³€í™˜**: ëª¨ë°”ì¼/ì›¹ í™˜ê²½ ìµœì í™”

### ì‹¤ë¬´ ì ìš©ì„ ìœ„í•œ íŒ

```python
# í•™ìŠµ ì•ˆì •í™”ë¥¼ ìœ„í•œ íŒ
def train_with_curriculum(model, dataloader, epochs):
    # ì ì§„ì  í•™ìŠµë¥  ê°ì†Œ
    scheduler = torch.optim.lr_scheduler.LinearLR(
        model.optimizer_G, start_factor=1.0, end_factor=0.1, total_iters=epochs//2
    )
    
    for epoch in range(epochs):
        for batch in dataloader:
            # ì •ê¸°ì ì¸ ê²€ì¦
            if epoch % 10 == 0:
                model.eval()
                validate_model(model, test_batch)
                model.train()
            
            losses = model.optimize_parameters(batch)
            
        scheduler.step()
        
        # ëª¨ë¸ ì²´í¬í¬ì¸íŠ¸ ì €ì¥
        if epoch % 50 == 0:
            torch.save(model.state_dict(), f'checkpoint_epoch_{epoch}.pth')
```

> Pix2Pixì™€ CycleGANì€ ì´ë¯¸ì§€ ìƒì„± ë¶„ì•¼ì˜ **íŒ¨ëŸ¬ë‹¤ì„ì„ ë°”ê¾¼ í˜ì‹ ì ì¸ ê¸°ìˆ **ë¡œ, í˜„ì¬ë„ ë‹¤ì–‘í•œ ë¶„ì•¼ì—ì„œ í™œë°œíˆ ì—°êµ¬ë˜ê³  ì‘ìš©ë˜ê³  ìˆë‹¤. íŠ¹íˆ **ë°ì´í„° ìš”êµ¬ì‚¬í•­ê³¼ ë¬¸ì œ íŠ¹ì„±**ì— ë”°ë¼ ì ì ˆí•œ ëª¨ë¸ì„ ì„ íƒí•˜ëŠ” ê²ƒì´ ì¤‘ìš”í•˜ë‹¤. {: .prompt-tip}